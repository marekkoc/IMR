{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created: 2020.07.23\n",
    "\n",
    "Modified: 2020.08.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the resolutions of all images in all databases,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from fastai.core import parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('functions')\n",
    "\n",
    "%aimport functions00\n",
    "\n",
    "from functions00 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************\n",
      "Settings:\n",
      "\t HOST: mmiv-ml-titan\n",
      "\t PATH_ROOT_DATA: /data-10tb/shared/skull/train-3d-iso\n",
      "\t PATH_GIT_HUB: /data-10tb/marek/github_codes/skull-stripping-1/fastai\n",
      "************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "get_host_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = PATH_GIT_HUB / '2.1_resample_jobs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53141"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth = PATH_ROOT_DATA / '*/*.nii.gz'\n",
    "files = glob.glob(str(pth))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info about all 3D iso images in the train-3d-iso folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get image sizes abot isotrobpic images in all databased. This information maight be helpful in decison about image while training NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to run in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shapes(f, index=0):\n",
    "    return (f, nib.load(f).get_fdata().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function runs fro all images in all databases!!!\n",
    "# in f1 we have a list of tuples (image_nama, shape)\n",
    "run = 0\n",
    "if run:\n",
    "    %%time\n",
    "    f1 = parallel(get_shapes, files, max_workers=64)\n",
    "    print(len(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df loaded from a file\n"
     ]
    }
   ],
   "source": [
    "# to create a df we can take a calculated result or loaded from a csv file\n",
    "if 'f1' in locals():\n",
    "    names, shapes = zip(*f1)\n",
    "    df = pd.DataFrame.from_dict({'file':names, 'shapes':shapes})\n",
    "    print('df from calculation')\n",
    "else:\n",
    "    df = pd.read_csv(save_folder / 'all_iso_images_shapes.csv')\n",
    "    print('df loaded from a file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save calculateed df for all images to a csv file\n",
    "save = 0\n",
    "if save:\n",
    "    save_name = f'all_iso_images_shapes.csv'    \n",
    "    pth = save_folder/save_name\n",
    "\n",
    "    df.to_csv(pth, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get size info about images in each database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_info(df, database):\n",
    "    un = df.shapes.unique()\n",
    "    vc = df.shapes.value_counts()\n",
    "    nu = df.shapes.nunique()\n",
    "    cn = df.shapes.count()\n",
    "    print(f'Shape info about: {database} 3D isotropic images\\n')\n",
    "    print(f'*** Total number of {database} images: {cn} ***\\n')\n",
    "    print(f'*** Nuber of unique shape values: {len(un)} ***\\n')\n",
    "    print(f'*** Unique shape and its counts: \\n{vc} ***')\n",
    "    #print(f'\\t*** Non unique values: {nu}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_db_shapes(df, database, save=False):\n",
    "    \"\"\"\n",
    "    enumrates shapes of images in db and save to csv file in needed.\n",
    "    \n",
    "    shapes_id = 1-N, index of possible image shapes in db\n",
    "    shapes_cnt = number of images wiht this shape within db\n",
    "    \"\"\"\n",
    "    df1 = df.copy()\n",
    "    vc = df1.shapes.value_counts()\n",
    "    for k, sh_all in enumerate(zip(vc, vc.index)):\n",
    "        shnr, sh = sh_all\n",
    "        #print(k, shnr, sh)\n",
    "        df1.loc[df1['shapes']==sh, 'shapes_id'] = k+1\n",
    "        df1.loc[df1['shapes']==sh, 'shapes_cnt'] = shnr\n",
    "        \n",
    "        df2 = df1.sort_values(by=['shapes_id'], inplace=False, ascending=False)\n",
    "\n",
    "    # set max dimension in the 'max_dims' column\n",
    "    r,c = df2.shape\n",
    "    mx = tuple(np.array([eval(t) for t in df2.shapes.values]).max(axis=0))\n",
    "    df2.insert(c, 'max_dims', [mx]*r, False)\n",
    "    #df1['max_dims'] = [mx]*df1.shape[0]\n",
    "    \n",
    "    if save:\n",
    "        save_name = f'{database}_iso_images_shapes.csv'    \n",
    "        pth = save_folder/save_name\n",
    "        df2.to_csv(pth, index=False)    \n",
    "    return max(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dim_for_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape info about: ADNI 3D isotropic images\n",
      "\n",
      "*** Total number of ADNI images: 25935 ***\n",
      "\n",
      "*** Nuber of unique shape values: 162 ***\n",
      "\n",
      "*** Unique shape and its counts: \n",
      "(211, 240, 170)    6381\n",
      "(192, 240, 170)    3445\n",
      "(235, 260, 170)    3015\n",
      "(204, 256, 170)    2256\n",
      "(200, 240, 170)     699\n",
      "                   ... \n",
      "(191, 239, 170)       3\n",
      "(154, 240, 170)       3\n",
      "(174, 240, 169)       3\n",
      "(211, 240, 171)       3\n",
      "(181, 239, 170)       3\n",
      "Name: shapes, Length: 162, dtype: int64 ***\n"
     ]
    }
   ],
   "source": [
    "%% time\n",
    "database = 'ADNI'\n",
    "\n",
    "df_out = df[df['file'].str.contains(database)]\n",
    "m = enumerate_db_shapes(df_out, database, save=True)\n",
    "max_dim_for_all.append(m)\n",
    "df_info(df_out, database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AIBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape info about: AIBL 3D isotropic images\n",
      "\n",
      "*** Total number of AIBL images: 2173 ***\n",
      "\n",
      "*** Nuber of unique shape values: 1 ***\n",
      "\n",
      "*** Unique shape and its counts: \n",
      "(192, 240, 170)    2173\n",
      "Name: shapes, dtype: int64 ***\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "database = 'AIBL'\n",
    "\n",
    "df_out = df[df['file'].str.contains(database)]\n",
    "m = enumerate_db_shapes(df_out, database, save=True)\n",
    "max_dim_for_all.append(m)\n",
    "df_info(df_out, database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IXI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape info about: IXI 3D isotropic images\n",
      "\n",
      "*** Total number of IXI images: 1743 ***\n",
      "\n",
      "*** Nuber of unique shape values: 5 ***\n",
      "\n",
      "*** Unique shape and its counts: \n",
      "(180, 240, 170)    1494\n",
      "(175, 240, 170)     222\n",
      "(180, 250, 170)      15\n",
      "(156, 240, 170)       6\n",
      "(168, 240, 170)       6\n",
      "Name: shapes, dtype: int64 ***\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "database = 'IXI'\n",
    "\n",
    "df_out = df[df['file'].str.contains(database)]\n",
    "m = enumerate_db_shapes(df_out, database, save=True)\n",
    "max_dim_for_all.append(m)\n",
    "df_info(df_out, database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape info about: PPMI 3D isotropic images\n",
      "\n",
      "*** Total number of PPMI images: 2250 ***\n",
      "\n",
      "*** Nuber of unique shape values: 11 ***\n",
      "\n",
      "*** Unique shape and its counts: \n",
      "(176, 240, 170)    1794\n",
      "(176, 256, 170)     279\n",
      "(192, 240, 170)      69\n",
      "(176, 250, 170)      51\n",
      "(256, 240, 170)      12\n",
      "(160, 240, 170)      12\n",
      "(175, 240, 170)      12\n",
      "(211, 253, 170)       9\n",
      "(192, 256, 170)       6\n",
      "(144, 240, 170)       3\n",
      "(176, 248, 170)       3\n",
      "Name: shapes, dtype: int64 ***\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "database = 'PPMI'\n",
    "\n",
    "df_out = df[df['file'].str.contains(database)]\n",
    "m = enumerate_db_shapes(df_out, database, save=True)\n",
    "max_dim_for_all.append(m)\n",
    "df_info(df_out, database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SALD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape info about: SALD 3D isotropic images\n",
      "\n",
      "*** Total number of SALD images: 1472 ***\n",
      "\n",
      "*** Nuber of unique shape values: 1 ***\n",
      "\n",
      "*** Unique shape and its counts: \n",
      "(176, 256, 170)    1472\n",
      "Name: shapes, dtype: int64 ***\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "database = 'SALD'\n",
    "\n",
    "df_out = df[df['file'].str.contains(database)]\n",
    "m = enumerate_db_shapes(df_out, database, save=True)\n",
    "max_dim_for_all.append(m)\n",
    "df_info(df_out, database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape info about: SLIM 3D isotropic images\n",
      "\n",
      "*** Total number of SLIM images: 1472 ***\n",
      "\n",
      "*** Nuber of unique shape values: 1 ***\n",
      "\n",
      "*** Unique shape and its counts: \n",
      "(176, 256, 170)    1472\n",
      "Name: shapes, dtype: int64 ***\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "database = 'SLIM'\n",
    "\n",
    "m = enumerate_db_shapes(df_out, database, save=True)\n",
    "max_dim_for_all.append(m)\n",
    "df_info(df_out, database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The maximal dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[282, 240, 250, 256, 256, 256]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_dim_for_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(max_dim_for_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai1",
   "language": "python",
   "name": "fastai1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
